# Classification task: 88,172-class word-level image classification
task: classifier
seed: 42

data:
  root: dataset/minDataset
  train_split: train
  val_split: val
  test_split: test
  img_height: 48
  img_width: 96
  num_workers: 8

model:
  mae_checkpoint: outputs/mae_pretrain  # outputs/mae_pretrain

training:
  classifier:
    output_dir: outputs/mae_pretrained_classifier
    freeze_encoder: true  # true: Linear Probing (只訓練 classifier), false: Fine-tuning (整個模型)
    num_train_epochs: 10
    per_device_train_batch_size: 128
    per_device_eval_batch_size: 128
    learning_rate: 5.0e-4
    lr_scheduler_type: cosine
    warmup_steps: 0
    warmup_ratio: 0.05
    weight_decay: 0.05
    adam_beta1: 0.9
    adam_beta2: 0.999
    adam_epsilon: 1.0e-8
    optim: adamw_torch
    max_grad_norm: 0.0
    logging_steps: 5000
    eval_steps: 10000
    save_steps: 10000
    save_total_limit: 3
    load_best_model_at_end: true
    metric_for_best_model: eval_loss
    greater_is_better: false
    gradient_accumulation_steps: 1
    mae_checkpoint_for_init: outputs/mae_pretrain  # outputs/mae_pretrain
    fp16: true
    report_to: none
